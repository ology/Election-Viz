#!/usr/bin/perl

=head1 PROGRAM

wikipedia-scrape

=head1 DESCRIPTION

Convert the wikipedia C<wikitable> for presidential election (votes) results by
state, into a columnar data file.

=head2 AUTHOR

Gene Boggs C<gene plus github at ology dot net>

=cut

use strict;
use warnings;

use HTML::TableExtract;
use LWP::UserAgent;

# Get the year from the commandline.
my $year = shift || 2012;

# Cached data file.
my $filename = sprintf 'data/%d.html', $year;

# String to hold the harvest or read results.
my $html = cached($year, $filename);

# Parse an entry with a TableExtract object.
my $tx = HTML::TableExtract->new;
$tx->parse($html);

# Find the right table.
my $found = 0;
for my $tab ($tx->tables) {
    # Process the results table, if found.
    if ($found) {
        process_table($tab);
        # This is the last table to consider.
        last;
    }
    else {
        # Look for the right table.
        for my $row ($tab->rows) {
            # Turn the row into a csv.
            my $string = join ',', map { defined $_ ? $_ : '' } @$row;
            # Stop looking if the csv is a signature match.
            if ( $string =~ /^Alabama,[\d-]+,.+$/ ) {
                $found++;
                last;
            }
        }
        # Rewind the rows if we've found the right table.
        redo if $found;
    }
}

sub process_table {
    my $table = shift;
    warn 'FOUND: Table [', join(',', $table->coords), "]\n";

    my (@candidates, @data);
    my $seen = 0;

    # Look for the right table.
    for my $row ($table->rows) {
#        warn join('|', @$row), "\n";
        if ( $seen || ($row->[0] && $row->[0] =~ /^State|Alabama$/) ) {
            # Note that we have seen the data.
            $seen++;

            # Sanitize the record.
            for my $cell ( @$row ) {
                next unless $cell;
                $cell =~ s/^.%$/%/;
                $cell =~ s/,//g;
            }

            push @data, $row;
        }
        else {
            # Save the sanitized candidate list.
            push @candidates,
                grep { defined && !/^I|Margin|State Total$/ } @$row;
        }

        # If none found, extract candidates from data header line.
        unless ( @candidates ) {
            # Save the sanitized candidate list.
            push @candidates,
                grep { defined && !/^%|Electors|Margin|State|Total?$/ } @{ $data[0] };
        }
    }
# DEBUGGING:
my $string = join '|', @candidates;
#my $string = join "\n", map { join '|', @$_ } @data;
print "$string\n";
}

sub cached { # Cache or harvest a wikipedia entry.
    my ($year, $filename) = @_;

    if (-e $filename) {
        warn "Cached data exists in $filename\n";
        # Read the cashed wikipedia text.
        local $/;
        open my $input, '<', $filename or die "Can't read $filename: $!";
        # Set the text for matching.
        $html = <$input>;
    }
    else {
        # Harvest from wikipedia.
        my $url = 'https://en.wikipedia.org/wiki/';
        $url .= 'United_States_presidential_election,_' . $year;
        warn "Harvesting new data from entry: '$url'\n";
        my $agent = LWP::UserAgent->new;
        my $response = $agent->get($url);
        # Die if no entry exists exists.
        my $error = 'Wikipedia does not have an article with this exact name';
        die "$error.\n" if $response->content =~ /$error/;
        # Cache the entry.
        $html = $response->content;
        open my $output, '>', $filename or die "Can't write to $filename: $!";
        print $output $html;
    }
    return $html;
}
