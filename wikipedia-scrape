#!/usr/bin/perl

=head1 PROGRAM

wikipedia-scrape

=head1 USAGE

 > perl wikipedia-scrape 1900 > 1900.dat

=head1 DESCRIPTION

Convert the wikipedia table of presidential election results by state, into a
columnar data file.

=head2 AUTHOR

Gene Boggs C<gene plus github at ology dot net>

=cut

use strict;
use warnings;

use HTML::TableExtract;
use LWP::UserAgent;

# Get the year from the commandline.
my $year = shift || 2012;

# Cached data file.
my $filename = sprintf 'data/%d.html', $year;

# String to hold the harvest or read results.
my $html = cached($year, $filename);

# Parse an entry with a TableExtract object.
my $tx = HTML::TableExtract->new;
$tx->parse($html);

# Get the election results table parts.
my ($candidates, $data) = table_locate($tx);

print join("\n",
    join("\t", @$candidates),
    join("\n", map { join("\t", @$_) } @$data)
) if @$candidates and @$data;

sub table_locate { # Find the right table in the entry.
    # Get a TableExtract object or fail.
    my $tx = shift || die "ERROR: No TableExtract object given.\n";

    # Traverse the tables, inspecing rows...
    my $found = 0;
    for my $tab ($tx->tables) {
        # Process the results table, if found.
        if ($found) {
            ($candidates, $data) = process_table($tab);
            # This is the last table to consider.
            last;
        } else {
            # Look for the right table.
            for my $row ($tab->rows) {
                # Turn the row into a csv.
                my $string = join ',', map { defined $_ ? $_ : '' } @$row;
                # Stop looking if the csv is a signature match.
                if ( $string =~ /^Alabama,[\d-]+,.+$/ ) {
                    $found++;
                    last;
                }
            }
            # Rewind the rows if we've found the right table.
            redo if $found;
        }
    }

    return $candidates, $data;
}

sub process_table { # Sanitize the table parts.
    my $table = shift;
    warn 'FOUND: Table [', join(',', $table->coords), "]\n";

    my (@candidates, @data);
    my $seen = 0;

    # Parse out the candidates and data.
    for my $row ($table->rows) {
        if ( $seen || ($row->[0] && $row->[0] =~ /^State|Alabama$/) ) {
            # Note that we have seen the data.
            $seen++;

            # Sanitize the record.
            for my $cell ( @$row ) {
                # Handle header data.
                $cell = 'XX' unless defined $cell; # Make undefined cells Xs.
                $cell =~ s/[^[:ascii:]]/-/g; # Replace non-ascii with -.
                $cell =~ s/^(?:\D+)?%$/P/g; # Replace a non-digit or lone % with P.
                $cell =~ s/#/N/g; # Replace #s with Ns.
                $cell =~ s/\n/ /g; # Replace newlines with a space.
                $cell =~ s/\s+/ /g; # Collapse multiple spaces.
                # Handle row data.
                $cell =~ s/,//g; # Remove commas.
                $cell =~ s/^([\d.-]+)%$/$1/g; # Remove the % sign from data.
                $cell =~ s/^(total.+)$/#$1/ig; # Comment total line.
            }

#            warn 'R: ',scalar(@$row),"\n"; # <- TESTING
            push @data, $row;
        } else {
            # Save the sanitized candidate list.
            push @candidates,
                grep { defined && !/^I|Margin|State Total$/ } @$row;
        }

        # If none found, parse header.
        unless ( @candidates ) {
            # Save the sanitized candidate list.
            push @candidates,
                grep { defined && !/^(?:%|P|Electors|Margin|State|Total)?$/ } @{ $data[0] };

            # Normalize headers.
            for (@{ $data[0] }) {
                $_ = 'N' unless /^(?:%|P|Electors|Margin|State|Total)?$/;
            }
        }
    }

    for (@candidates) {
        s/\n/ /g; # Replace newlines with a space.
        s/\s+/ /g; # Collapse multiple spaces.
    }

    return \@candidates, \@data;
}

sub cached { # Cache or harvest a wikipedia entry.
    my ($year, $filename) = @_;

    if (-e $filename) {
        warn "Cached data exists in $filename\n";
        # Read the cashed wikipedia text.
        local $/;
        open my $input, '<', $filename or die "Can't read $filename: $!";
        # Set the text for matching.
        $html = <$input>;
    } else {
        # Harvest from wikipedia.
        my $url = 'https://en.wikipedia.org/wiki/';
        $url .= 'United_States_presidential_election,_' . $year;
        warn "Harvesting new data from entry: '$url'\n";
        my $agent = LWP::UserAgent->new;
        my $response = $agent->get($url);
        # Die if no entry exists exists.
        my $error = 'Wikipedia does not have an article with this exact name';
        die "$error.\n" if $response->content =~ /$error/;
        # Cache the entry.
        $html = $response->content;
        open my $output, '>', $filename or die "Can't write to $filename: $!";
        print $output $html;
    }
    return $html;
}
